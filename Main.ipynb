{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94bac4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7436c41e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO: add a field for trusted users. A user is trusted if they're a moderator or a long-time sub.\n",
    "# TODO: Discard bot messages. Consider also discarding mod messages since they're often the only ones allowed to send links.\n",
    "train = 0\n",
    "test = 0\n",
    "data = {} \n",
    "# of the form:\n",
    "# {\"channel1\":\n",
    "#    {\n",
    "#     \"messages\": [\"messsage1\", \"message2\"...],\n",
    "#     \"bad_messages\": [4, 18...], (indices of messages)\n",
    "#     \"viewers\": 482 (average)\n",
    "#    }\n",
    "#  \"channel2\":\n",
    "#   {...}\n",
    "# }\n",
    "\n",
    "\n",
    "# look through every data file\n",
    "for filename in os.listdir(\"FullData\"):\n",
    "    if os.path.isfile(\"FullData/\" + filename):\n",
    "        # get channel name\n",
    "        channel = filename.split(\"#\")[1].split(\".\")[0]\n",
    "        if not channel in data:\n",
    "            data[channel] = {\"viewers\": [], \"messages\": [], \"bad_messages\": []}\n",
    "        with open(\"FullData/\" + filename, encoding='utf-8') as file:\n",
    "            lines = []\n",
    "            for line in file.readlines():\n",
    "                # only care about timestamped lines. Others are overhead data that we don't mind.\n",
    "                if line[0] == \"[\":\n",
    "                    # get rid of the timestamp, we only want the message itself.\n",
    "                    line = line[line.find(\"] \")+2:]\n",
    "                    # check for standard message sent by a user.\n",
    "                    if line[0] == \"<\":\n",
    "                        lines.append(line)\n",
    "                    # check for overhead message stating viewer count.\n",
    "                    elif line[0:8] == \"VIEWERS:\":\n",
    "                        # for now add every viewer count to a list for averaging later on.\n",
    "                        data[channel][\"viewers\"].append(int(line[9:].replace(\"\\xa0\", \"\")))\n",
    "                    # check for overhead message stating a user was banned\n",
    "                    elif line[0:4] == \"BAN:\":\n",
    "                        # find most recent message sent by banned user and mark as bad message.\n",
    "                        for i, msg in reversed(list(enumerate(lines))):\n",
    "                            if line[5:].split(\" \")[0] + \">\" in msg:\n",
    "                                data[channel][\"bad_messages\"].append(len(data[channel][\"messages\"]) + i)\n",
    "                                break\n",
    "                    # check for overhead message stating a message was deleted.\n",
    "                    elif line[0:8] == \"DELETED:\":\n",
    "                        # find the deleted message and mark it as bad message.\n",
    "                        for i, msg in reversed(list(enumerate(lines))):\n",
    "                            if line[9:].split(\" (\")[0] + \"> \" + line[line.find(\" (\")+2:-1] in msg:\n",
    "                                data[channel][\"bad_messages\"].append(i)\n",
    "                                break\n",
    "            # sort bad message indices.\n",
    "            data[channel][\"bad_messages\"] = sorted(set(data[channel][\"bad_messages\"]))\n",
    "            # remove names from messages and add to data.\n",
    "            for temp in lines:\n",
    "                temp = temp[temp.find(\">\")+2:]\n",
    "                # non-functioning attempt at anonomizing @-mentions.\n",
    "                #index = temp.find(\"@\")\n",
    "                #while index != -1:\n",
    "                #    temp.replace(temp[index:temp.find(\" \", index)], \"@user\")\n",
    "                #    index = temp.find(\"@\", index+1)\n",
    "                data[channel][\"messages\"].append(temp)\n",
    "# average viewer counts by channel and remove channels without viewer data.\n",
    "removals = []\n",
    "for channel in data.keys():\n",
    "    if len(data[channel][\"viewers\"]) == 0:\n",
    "        removals.append(channel)\n",
    "    else:\n",
    "        avg_viewers = int(sum(data[channel][\"viewers\"]) / len(data[channel][\"viewers\"]))\n",
    "        data[channel][\"viewers\"] = avg_viewers\n",
    "for channel in removals:\n",
    "    data.pop(channel)\n",
    "discarded_channels = []\n",
    "for channel in data.keys():\n",
    "    if data[channel][\"viewers\"] >= 10000 or len(data[channel][\"bad_messages\"]) == 0:\n",
    "        discarded_channels.append(channel)\n",
    "\n",
    "formatted_data = []\n",
    "for channel in data.keys():\n",
    "    if channel in discarded_channels:\n",
    "        continue\n",
    "    next_bad = 0\n",
    "    for index in range(len(data[channel][\"messages\"])):\n",
    "        row = []\n",
    "        if next_bad < len(data[channel][\"bad_messages\"]) and data[channel][\"bad_messages\"][next_bad] == index:\n",
    "            row = [\"bad\", data[channel][\"messages\"][index], channel]\n",
    "            next_bad += 1\n",
    "        else:\n",
    "            row = [\"good\", data[channel][\"messages\"][index], channel]\n",
    "        formatted_data.append(row)\n",
    "df = pd.DataFrame(formatted_data, columns=[\"status\", \"message\", \"channel\"])\n",
    "# Undersampling the training data\n",
    "temp = df.groupby(['status']).size()\n",
    "\n",
    "res = []\n",
    "res.append(df[df.status == \"bad\"])\n",
    "indices = df[df.status == \"good\"].index\n",
    "random_indices = np.random.choice(indices, temp[\"bad\"]*9, replace=False)\n",
    "res.append(df.loc[random_indices])\n",
    "undersampled_data = pd.concat(res)\n",
    "train, test = train_test_split(undersampled_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4aacde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(df)\n",
    "del(data)\n",
    "del(lines)\n",
    "del(formatted_data)\n",
    "del(temp)\n",
    "del(res)\n",
    "del(indices)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d18fadc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>message</th>\n",
       "      <th>channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21159337</th>\n",
       "      <td>good</td>\n",
       "      <td>do it anyway\\n</td>\n",
       "      <td>elajjaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19300702</th>\n",
       "      <td>good</td>\n",
       "      <td>Happy near year guys\\n</td>\n",
       "      <td>dannyaarons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24211179</th>\n",
       "      <td>good</td>\n",
       "      <td>nerf hunters? why ?\\n</td>\n",
       "      <td>gingitv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21433948</th>\n",
       "      <td>good</td>\n",
       "      <td>BBoomer\\n</td>\n",
       "      <td>elajjaz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11850494</th>\n",
       "      <td>good</td>\n",
       "      <td>LUL\\n</td>\n",
       "      <td>39daph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         status                 message      channel\n",
       "21159337   good          do it anyway\\n      elajjaz\n",
       "19300702   good  Happy near year guys\\n  dannyaarons\n",
       "24211179   good   nerf hunters? why ?\\n      gingitv\n",
       "21433948   good               BBoomer\\n      elajjaz\n",
       "11850494   good                   LUL\\n       39daph"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf29bae6",
   "metadata": {},
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "pipe = Pipeline([('count_vectorizer', CountVectorizer()), ('tfidf', TfidfTransformer()),('bayes', MultinomialNB())])\n",
    "pipe.fit(train['message'], train['status'])\n",
    "\n",
    "predict = pipe.predict(test['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab6de34",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report\n",
    "good_bad_count = {\"good\": 0, \"bad\": 0}\n",
    "for guess in predict:\n",
    "        good_bad_count[guess] += 1\n",
    "print(good_bad_count)\n",
    "print(classification_report(test['status'], predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9b5d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saker att testa: Support Vector Machines, XGBoost, K Nearest Neighbors, XLNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afdfa9f",
   "metadata": {},
   "source": [
    "# Naive-Bayes with undersampled training data.\n",
    "\n",
    "pipe = Pipeline([('count_vectorizer', CountVectorizer(binary=True)), ('tfidf', TfidfTransformer()),('bayes', MultinomialNB())])\n",
    "pipe.fit(undersampled_train['message'], undersampled_train['status'])\n",
    "\n",
    "predict = pipe.predict(test['message'])\n",
    "\n",
    "good_bad_count = {\"good\": 0, \"bad\": 0}\n",
    "for guess in predict:\n",
    "        good_bad_count[guess] += 1\n",
    "print(good_bad_count)\n",
    "print(classification_report(test['status'], predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a0d774",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "pipe = Pipeline([('count_vectorizer', CountVectorizer()), \n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('bayes', MultinomialNB())])\n",
    "grid = GridSearchCV(pipe, {\n",
    "    'count_vectorizer__binary':(True, False),\n",
    "    'count_vectorizer__ngram_range':((1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3)),\n",
    "    'bayes__alpha': (0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0),\n",
    "    'bayes__fit_prior': (True, False)\n",
    "})\n",
    "grid.fit(train['message'], train['status'])\n",
    "predict = grid.predict(test['message'])\n",
    "\n",
    "print(\"Best parameter (CV score=%0.3f):\" % grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7707f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': 103199, 'bad': 2229}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.94      0.20      0.33     10347\n",
      "        good       0.92      1.00      0.96     95081\n",
      "\n",
      "    accuracy                           0.92    105428\n",
      "   macro avg       0.93      0.60      0.65    105428\n",
      "weighted avg       0.92      0.92      0.90    105428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes with full data and selected parameters\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(\n",
    "        binary=True\n",
    "    )),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('bayes', MultinomialNB(\n",
    "        #alpha=grid.best_params_[\"bayes__alpha\"],\n",
    "        #fit_prior=grid.best_params_[\"bayes__fit_prior\"]\n",
    "    ))\n",
    "])\n",
    "pipe.fit(train['message'], train['status'])\n",
    "\n",
    "predict = pipe.predict(test['message'])\n",
    "\n",
    "good_bad_count = {\"good\": 0, \"bad\": 0}\n",
    "for guess in predict:\n",
    "        good_bad_count[guess] += 1\n",
    "print(good_bad_count)\n",
    "print(classification_report(test['status'], predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceec7f3",
   "metadata": {},
   "source": [
    "# Naive Bayes with undersampled data and selected parameters\n",
    "\n",
    "\n",
    "pipe = Pipeline([('count_vectorizer', CountVectorizer(binary=True, ngram_range=(1, 1))), ('tfidf', TfidfTransformer()),('bayes', MultinomialNB(alpha=0.4, fit_prior=False))])\n",
    "pipe.fit(undersampled_train['message'], undersampled_train['status'])\n",
    "\n",
    "predict = pipe.predict(test['message'])\n",
    "\n",
    "good_bad_count = {\"good\": 0, \"bad\": 0}\n",
    "for guess in predict:\n",
    "        good_bad_count[guess] += 1\n",
    "print(good_bad_count)\n",
    "print(classification_report(test['status'], predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "194f30b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': 95677, 'bad': 9751}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.39      0.37      0.38     10347\n",
      "        good       0.93      0.94      0.93     95081\n",
      "\n",
      "    accuracy                           0.88    105428\n",
      "   macro avg       0.66      0.65      0.66    105428\n",
      "weighted avg       0.88      0.88      0.88    105428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([('count_vectorizer', CountVectorizer(binary=True)), ('tfidf', TfidfTransformer()), ('scaler', StandardScaler(with_mean=False)), ('svc', LinearSVC())])\n",
    "pipe.fit(train['message'], train['status'])\n",
    "\n",
    "predict = pipe.predict(test['message'])\n",
    "\n",
    "good_bad_count = {\"good\": 0, \"bad\": 0}\n",
    "for guess in predict:\n",
    "        good_bad_count[guess] += 1\n",
    "print(good_bad_count)\n",
    "print(classification_report(test['status'], predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb13a94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': 99829, 'bad': 5599}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.62      0.34      0.44     10347\n",
      "        good       0.93      0.98      0.95     95081\n",
      "\n",
      "    accuracy                           0.91    105428\n",
      "   macro avg       0.78      0.66      0.70    105428\n",
      "weighted avg       0.90      0.91      0.90    105428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(binary=True)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('svc', LinearSVC(max_iter = 50000, dual = False))\n",
    "])\n",
    "pipe.fit(train['message'], train['status'])\n",
    "\n",
    "predict = pipe.predict(test['message'])\n",
    "\n",
    "good_bad_count = {\"good\": 0, \"bad\": 0}\n",
    "for guess in predict:\n",
    "        good_bad_count[guess] += 1\n",
    "print(good_bad_count)\n",
    "print(classification_report(test['status'], predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83026d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': 78929, 'bad': 26499}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.26      0.68      0.38     10347\n",
      "        good       0.96      0.80      0.87     95081\n",
      "\n",
      "    accuracy                           0.78    105428\n",
      "   macro avg       0.61      0.74      0.62    105428\n",
      "weighted avg       0.89      0.78      0.82    105428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(binary=True)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('svc', LinearSVC(max_iter = 50000, dual = False, class_weight='balanced'))\n",
    "])\n",
    "pipe.fit(train['message'], train['status'])\n",
    "\n",
    "predict = pipe.predict(test['message'])\n",
    "\n",
    "good_bad_count = {\"good\": 0, \"bad\": 0}\n",
    "for guess in predict:\n",
    "        good_bad_count[guess] += 1\n",
    "print(good_bad_count)\n",
    "print(classification_report(test['status'], predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b20d3c",
   "metadata": {},
   "source": [
    "pipe = Pipeline([('count_vectorizer', CountVectorizer()), ('tfidf', TfidfTransformer()),('svc', SVC())])\n",
    "pipe.fit(undersampled_train['message'], undersampled_train['status'])\n",
    "\n",
    "predict = pipe.predict(test['message'])\n",
    "\n",
    "good_bad_count = {\"good\": 0, \"bad\": 0}\n",
    "for guess in predict:\n",
    "        good_bad_count[guess] += 1\n",
    "print(good_bad_count)\n",
    "print(classification_report(test['status'], predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b3c311b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter (CV score=0.973):\n",
      "{'svc__C': 0.8, 'svc__class_weight': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pipe = Pipeline([('count_vectorizer', CountVectorizer(binary=True)), \n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('scaler', StandardScaler(with_mean=False)),\n",
    "                 ('svc', LinearSVC(dual = False))])\n",
    "#grid = GridSearchCV(pipe, {\n",
    "#    'count_vectorizer__binary':(True, False),\n",
    "#    'count_vectorizer__ngram_range': ((1, 1), (1, 2), (2, 2), (1, 3), (2, 3), (3, 3)),\n",
    "#    'svc__C': (0.1, 0.5, 1.0, 5.0, 10.0),\n",
    "#    'svc__kernel': (\"linear\", \"poly\", \"rbf\", \"sigmoid\", \"precomputed\"),\n",
    "#    'svc__degree': (1, 2, 3, 4, 5, 10),\n",
    "#    'svc__gamma': (\"auto\", \"scale\"),\n",
    "#    'svc__shrinking': (True, False),\n",
    "#    'svc__probability': (True, False),\n",
    "#    'svc__tol': (0.001, 0.005, 0.01, 0.05, 0.1),\n",
    "#    'svc__class_weight': (None, \"balanced\")})\n",
    "\n",
    "grid = GridSearchCV(pipe, {\n",
    "    'svc__C': (0.8, 0.9, 1.0, 1.1),\n",
    "    #'svc__kernel': (\"linear\", \"poly\", \"rbf\", \"sigmoid\", \"precomputed\"),\n",
    "    #'svc__degree': (2, 3, 4),\n",
    "    #'svc__gamma': (\"auto\", \"scale\"),\n",
    "    #'svc__shrinking': (True, False),\n",
    "    #'svc__probability': (True, False),\n",
    "    'svc__class_weight': (None, \"balanced\"),\n",
    "    #'svc__tol': (0.009, 0.01, 0.011)\n",
    "})\n",
    "grid.fit(train['message'], train['status'])\n",
    "predict = grid.predict(test['message'])\n",
    "\n",
    "print(\"Best parameter (CV score=%0.3f):\" % grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19ce32ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'good': 10090, 'bad': 199}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.18      0.23      0.20       149\n",
      "        good       0.99      0.98      0.99     10140\n",
      "\n",
      "    accuracy                           0.97     10289\n",
      "   macro avg       0.58      0.61      0.59     10289\n",
      "weighted avg       0.98      0.97      0.97     10289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(\n",
    "        binary=True\n",
    "    )),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('svc', LinearSVC(\n",
    "        C=grid.best_params_[\"svc__C\"],\n",
    "        #kernel=grid.best_params_[\"svc__kernel\"],\n",
    "        #degree=grid.best_params_[\"svc__degree\"],\n",
    "        #gamma=grid.best_params_[\"svc__gamma\"],\n",
    "        #shrinking=grid.best_params_[\"svc__shrinking\"],\n",
    "        #probability=grid.best_params_[\"svc__probability\"],\n",
    "        class_weight=grid.best_params_[\"svc__class_weight\"],\n",
    "        #tol=grid.best_params_[\"svc__tol\"],\n",
    "        dual=False,\n",
    "        max_iter=10000\n",
    "    ))\n",
    "])\n",
    "pipe.fit(train['message'], train['status'])\n",
    "\n",
    "predict = pipe.predict(test['message'])\n",
    "\n",
    "good_bad_count = {\"good\": 0, \"bad\": 0}\n",
    "for guess in predict:\n",
    "        good_bad_count[guess] += 1\n",
    "print(good_bad_count)\n",
    "print(classification_report(test['status'], predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d4b13e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18980\\2166949942.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m pipe = Pipeline([('count_vectorizer', CountVectorizer()), \n\u001b[0m\u001b[0;32m      3\u001b[0m                  \u001b[1;33m(\u001b[0m\u001b[1;34m'tfidf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                  \u001b[1;33m(\u001b[0m\u001b[1;34m'scaler'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                  ('svc', SVC())])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
